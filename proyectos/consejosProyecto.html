<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <title>Title</title>

</head>

<body>
<h2>Consejos y comentarios sobre el proyecto</h2>
<h3>Reproducibilidad</h3>
<p>Recordad que es muy importante que el proceso que realicéis durante el proyecto quede bien explicado en la memoria. Valoraremos especialmente la reproducibilidad del proyecto, es decir, que seamos capaces de hacerlo de igual forma que lo hicísteis vosotros.</p>
<h3>Proyectos sobre Acepta El Reto</h3>
<p>Actualmente estamos comenzando a trabajar en el análisis de los datos extraídos de <a target="_blank" href="https://www.aceptaelreto.com/">Acepta el reto</a>, un almacen de ejercicios de programación y juez en línea, desarrollado por Marco Antonio Gómez Martín y Pedro Pablo Gómez Martín, profesores de nuestra  Facultad y utilizado en algunas asignaturas que se imparten actualmente. Os animamos a que propongáis algunos proyectos que sirvan para explorar las relaciones que se producen entre los distintos usuarios de la herramienta y para analizar los ejercicios que se realizan.</p>
<h3>Datasets</h3>
<p>Existen muchos datasets o conjuntos de datos ya creados y que pueden ser usados para la realización del proyecto. Recordad que si elegís la opción 1 de proyecto y usáis datasets que ya almacenan información en forma de grafo os perjudicará en la nota del proyecto.</p>
<p>Algunos sitios en los que podéis consultar algunos datasets son los siguientes:</p>
<ul>
<li><a target="_blank" href="http://aws.amazon.com/datasets">Datasets de Amazon</a></li>
<li><a target="_blank" href="http://www.kdnuggets.com/datasets/index.html">Datasets for Data mining</a></li>
<li><a target="_blank" href="http://blog.bigml.com/2013/02/28/data-data-data-thousands-of-public-data-sources/#comment-7538">Artículo sobre Datasets de BigML</a></li>
<li><a target="_blank" href="http://kevinchai.net/datasets">Página sobre datasets de Kevin Chai</a></li>
<li><a target="_blank" href="http://snap.stanford.edu/data/">Stanford Large Dataset (SNAP)</a></li>
<li><a target="_blank" href="http://www.imdb.com/interfaces">Dataset de IMDB (películas)</a></li>
<li><a target="_blank" href="http://www.trustlet.org/wiki/Epinions_datasets">Dataset de Epinions</a></li>
<li><a target="_blank" href="http://labrosa.ee.columbia.edu/millionsong/">Million song dataset (Música)</a></li>
<li><a target="_blank" href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/">Book Crossing dataset (Libros)</a></li>
<li><a target="_blank" href="http://statweb.stanford.edu/~tibs/ElemStatLearn/data.html">Datasets usados en el libro "The elements of statistical learning"</a></li>
<li><a target="_blank" href="http://archive.ics.uci.edu/ml/index.html">UCI Machine Learning Repository</a></li>
</ul>
<p>Tanto si el dataset lo construís vosotros como si lo descargáis será necesario que lo filtréis (eliminando información innecesaria, reduciendo el dataset, etc) y que lo convirtáis a forma de grafo. <strong>Detallad claramente cuál es el significado de los nodos y aristas y del proceso seguido para hacer estas transformaciones y obtener el grafo final a analizar</strong>.</p>
<h3>Extracción de datos usando librerías y APIs públicas</h3>
<p>Si no encontráis un dataset que os satisfaga siempre podéis creároslos vosotros mismos a partir de toda la información que se guarda en infinidad de sitios web. Antes de intentar implementaros vuestros propios web crawlers os recomendamos que echéis un vistazo a los numerosos sitios web que hay con APIs públicas. Un sitio donde encontrar un montón de información sobre ellas es <a target="_blank" href="http://www.programmableweb.com/apis/directory">ProgramableWeb</a> donde, además de un montón de APIs, podéis encontrar tutoriales y librerías para extraer la información de ellas.</p>
<p>Si esto tampoco os os sirve entonces buscad librerías (como <a href="https://cv4.ucm.es/moodle/imdbpy.sourceforge.net">IMDBpy</a> o <a href="https://code.google.com/p/crawler4j/">crawler4j</a>) y sitios (como <a target="_blank" href="http://support.import.io/knowledgebase/articles/251955-what-is-import-io">Import.io</a>) que os ayuden a hacer el trabajo de crawling.</p>
<h3>Herramientas alternativas de visualización</h3>
<p>Además de Gephi existen otras herramientas alternativas para visualizar grafos, por si queréis usar otras. Las más populares son:</p>
<ul>
<li><a target="_blank" href="http://pajek.imfm.si/doku.php">Pajek</a></li>
<li><a target="_blank" href="http://nodexl.codeplex.com/">NodeXL</a> (plugin para Excel)</li>
<li><a target="_blank" href="http://snap.stanford.edu/">SNAP</a> (librería para Network Analysis)</li>
<li><a target="_blank" href="http://igraph.org/index.html">iGraph</a> (librerías en distintos lenguajes, entre los que destaca R)</li>
<li><a target="_blank" href="http://networkx.github.io/">NetworkX</a> (Python)</li>
<li><a target="_blank" href="http://www.cytoscape.org/">Cytoscape</a></li>
</ul>
<h3>Programando con Gephi</h3>
<p>También os recordamos que <a target="_blank" href="http://gephi.github.io/developers/">Gephi tiene una API </a>de programación que podéis utilizar en la realización de vuestros proyectos.</p>
<p></p>
<p></p>
<p></p>
</body>
</html>